## Ollama Docker FastAPI

This is a simple Dockerized FastAPI application that returns a JSON response.
It uses ollama to run llama3 model inside a docker container and serve the model as a FastAPI application.

The video tutorial is here: [https://www.youtube.com/bitfumes](https://www.youtube.com/bitfumes)